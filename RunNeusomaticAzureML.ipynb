{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from azureml.core import Workspace\n",
    " \n",
    "#ws = Workspace.create(name='neusomaticws', subscription_id='3d890015-29d9-4a08-bad3-8e41a8c8c199',\n",
    "#                      resource_group='hpc-roche-neusomatic',\n",
    "#                      exist_ok=True,\n",
    "#                      location='westeurope' \n",
    "#                     )\n",
    "#ws.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/3d890015-29d9-4a08-bad3-8e41a8c8c199/resourceGroups/hpc-roche-neusomatic/providers/Microsoft.MachineLearningServices/workspaces/neusomaticws',\n",
       " 'name': 'neusomaticws',\n",
       " 'location': 'westeurope',\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces',\n",
       " 'workspaceid': 'a1186608-73dc-4c0e-a933-5255238b786a',\n",
       " 'description': '',\n",
       " 'friendlyName': '',\n",
       " 'creationTime': '2019-01-17T14:24:40.4006018+00:00',\n",
       " 'containerRegistry': '/subscriptions/3d890015-29d9-4a08-bad3-8e41a8c8c199/resourcegroups/hpc-roche-neusomatic/providers/microsoft.containerregistry/registries/neusomaticws9296802368',\n",
       " 'keyVault': '/subscriptions/3d890015-29d9-4a08-bad3-8e41a8c8c199/resourcegroups/hpc-roche-neusomatic/providers/microsoft.keyvault/vaults/neusomaticws9199451487',\n",
       " 'applicationInsights': '/subscriptions/3d890015-29d9-4a08-bad3-8e41a8c8c199/resourcegroups/hpc-roche-neusomatic/providers/microsoft.insights/components/neusomaticws7558457736',\n",
       " 'identityPrincipalId': '99ca2d15-e5da-4a68-bbf6-f581ddcc8762',\n",
       " 'identityTenantId': '72f988bf-86f1-41af-91ab-2d7cd011db47',\n",
       " 'identityType': 'SystemAssigned',\n",
       " 'storageAccount': '/subscriptions/3d890015-29d9-4a08-bad3-8e41a8c8c199/resourcegroups/hpc-roche-neusomatic/providers/microsoft.storage/storageaccounts/neusomaticws4311691687'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the configuration file.\n",
    "#ws.write_config() #config is saved in .azureml/config.json\n",
    "\n",
    "# Use this code to load the workspace from \n",
    "# other scripts and notebooks in this directory.\n",
    "ws = Workspace.from_config()\n",
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Configure the Azure ML Compute and Storage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get azure storage key\n",
    "#Assuming there is a single line with a key  \n",
    "def get_storage_key(file):\n",
    "    File = open(file, 'r', 0)\n",
    "    return File.readlines()[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspacefilestore AzureFile\n",
      "workspaceblobstore AzureBlob\n",
      "ds_neus AzureBlob\n",
      "ds_test AzureBlob\n",
      "ds_res AzureBlob\n"
     ]
    }
   ],
   "source": [
    "#list all datastores registered in current workspace\n",
    "datastores = ws.datastores\n",
    "for name, ds in datastores.items():\n",
    "    print(name, ds.datastore_type)\n",
    "    \n",
    "#print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "#get named datastore from current workspace\n",
    "#ds_weights = Datastore.get(ws, datastore_name='ds_weights')\n",
    "#ds_tracks = Datastore.get(ws, datastore_name='ds_tracks')\n",
    "ds_test = Datastore.get(ws, datastore_name='ds_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Set Compute Resources in Azure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following options are available:\n",
    "* **Run-based creation** creates a compute target at runtime. The compute is automatically created for your run. The cluster scales up to the number of max_nodes that you specify in your run config. The compute is deleted automatically once the run completes.\n",
    "\n",
    "* **Persistent Compute**. A persistent Azure Machine Learning Compute can be reused across jobs. The compute can be shared with other users in the workspace and is kept between jobs.\n",
    "\n",
    "* **Remote Virtual Machines**. An arbitrary remote VM, as long as it's accessible from Azure Machine Learning service.\n",
    "\n",
    "* **Azure Batch**. Azure Batch is used to run large-scale parallel and high-performance computing (HPC) applications efficiently in the cloud. AzureBatchStep can be used in an Azure Machine Learning Pipeline to submit jobs to an Azure Batch pool of machines. \n",
    "\n",
    "See https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#vm for more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option #4.  Create a Data Science VM \n",
    "* VM has many dependencies as a part of the OS image\n",
    "\n",
    "Testing now.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new DSVM.\n",
      "\n",
      "        DEPRECATED\n",
      "        This class will be deprecated soon and we will remove support for it in an upcoming release.\n",
      "        Please use the \"AmlCompute\" class instead, or spin up a VM in Azure and attach it using RemoteCompute().\n",
      "        Use !help AmlCompute to learn more.\n",
      "        \n",
      "Creating..........................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Waiting one minute for ssh to be accessible\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import DsvmCompute\n",
    "import time\n",
    "\n",
    "dsvm_name = 'dsvmgpu'\n",
    "try:\n",
    "    dsvm_compute = DsvmCompute(ws, dsvm_name)\n",
    "    print('Found an existing DSVM.')\n",
    "except:\n",
    "    print('Creating a new DSVM.')\n",
    "    dsvm_config = DsvmCompute.provisioning_configuration(vm_size = \"Standard_NC6\") # Standard_D2s_v3\n",
    "    dsvm_compute = DsvmCompute.create(ws, name = dsvm_name, provisioning_configuration = dsvm_config)\n",
    "    dsvm_compute.wait_for_completion(show_output = True)\n",
    "    print(\"Waiting one minute for ssh to be accessible\")\n",
    "    time.sleep(90) # Wait for ssh to be accessible\n",
    "\n",
    "compute_target = dsvm_compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Control \n",
    "\n",
    "#### Option 1: Execute with Run Configurations (skip for now).\n",
    "* execute once the compute resource is defined\n",
    "* Select between Options 1-4\n",
    "* Define conda and pip dependencies\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Option 2: Define Estimators\n",
    "* execute once the compute resource is defined\n",
    "* Select between Options 1-4\n",
    "* Define conda and pip dependencies\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-9-b0c7d1cb3bd9>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-b0c7d1cb3bd9>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    --region_bed region.bed \t--tumor_bam tumor.bam \t--normal_bam normal.bam \t--work work_train \t--truth_vcf truth.vcf \t--min_mapq 10 \t--number_threads 10 \t--scan_alignments_binary ../bin/scan_alignments\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment, Run\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "#Original script is called as follows:\n",
    "# preprocess.py --mode train \n",
    "#--reference GRCh38.fa \\\n",
    "#--region_bed region.bed \\\n",
    "#--tumor_bam tumor.bam \\\n",
    "#--normal_bam normal.bam \\\n",
    "#--work work_train \\\n",
    "#--truth_vcf truth.vcf \\\n",
    "#--min_mapq 10 \\\n",
    "#--number_threads 10 \\\n",
    "#--scan_alignments_binary ../bin/scan_alignments\n",
    "\n",
    "#conda install zlib=1.2.11 numpy=1.15.4 scipy=1.2.0 cmake=3.13.2 imageio=2.5.0\n",
    "#$conda install pysam=0.15.2 pybedtools=0.8.0 samtools=1.9 tabix=0.2.6 bedtools=2.27.1 biopython=1.73 -c bioconda\n",
    "#$conda install pytorch=1.0.1 torchvision=0.2.1 cudatoolkit=8.0 -c pytorch\n",
    "\n",
    "script_params = {\n",
    "    '--reference': ds_rphi.as_download(),\n",
    "    '--work': 'work_train',\n",
    "    '--region_bed': ds_weights.as_download(),\n",
    "    '--truth-tracks-path': ds_tracks.as_download()\n",
    "}\n",
    "\n",
    "# compute_target is a CPU cluster\n",
    "# my_compute_target is a default compute from AzureML (not tested)\n",
    "est = Estimator(source_directory=source_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,  \n",
    "                entry_script='train.py',\n",
    "                #pip_packages=['pynvrtc'],\n",
    "                conda_packages=['pytorch','scipy','numpy','scikit-learn','tqdm','cython','torchvision','cudatoolkit=9.0','matplotlib'])\n",
    "\n",
    "#ImportError: .../torch/lib/libtorch.so.1: undefined symbol: nvrtcGetProgramLogSize\n",
    "#Testing pytorch-cpu version -> problem \n",
    "#ResolvePackageNotFound: torchvision-cpu, pytorch-cpu\n",
    "\n",
    "#OR add cudatoolkit\n",
    "\n",
    "# Create the experiment\n",
    "experiment = Experiment(workspace = ws, name = \"Neusomatic-GPU\")\n",
    "#my_compute_target = run_system_managed_temp.amlcompute\n",
    "\n",
    "run = experiment.submit(est)\n",
    "run.wait_for_completion(show_output = True)\n",
    "\n",
    "#run_system_managed_temp = experiment.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run\n",
    "#run.log(name, value, description='')\n",
    "\n",
    "# ImportError: /azureml-envs/azureml_aa3800697c3da90356674c5d162cf01e/lib/python3.6/site-packages/torch/lib/libtorch.so.1: undefined symbol: nvrtcGetProgramLogSize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
