{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Configure the Azure ML Datastore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using version 1.0.41 of the Azure ML SDK\n"
     ]
    }
   ],
   "source": [
    "# Import Azure ML API SDK. The SDK is installed implicitly with the latest\n",
    "# version of the CLI in your default python environment\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")\n",
    "\n",
    "#to be replaced with Roche's workspace \n",
    "#ws = Workspace.from_config(path='/home/lukasz/notebooks/azureml/python/aml_config/config.json')\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created  /home/cerndev/common/azure/data\n",
      "Created  /home/cerndev/common/azure/data/weights\n",
      "Created  /home/cerndev/common/azure/data/rphi\n",
      "Created  /home/cerndev/common/azure/data/tracks\n"
     ]
    }
   ],
   "source": [
    "#Setup the data source\n",
    "\n",
    "# Current directory structure: \n",
    "#- data\n",
    "# -- weights\n",
    "# -- rphi\n",
    "# -- tracks\n",
    "data_folder = os.path.join(os.getcwd(), 'data')\n",
    "weights_folder = os.path.join(data_folder, 'weights')\n",
    "rphi_folder = os.path.join(data_folder, 'rphi')\n",
    "tracks_folder = os.path.join(data_folder, 'tracks')\n",
    "\n",
    "os.makedirs(data_folder, exist_ok = True)\n",
    "\n",
    "print (\"Created \", data_folder)\n",
    "print (\"Created \", weights_folder)\n",
    "print (\"Created \", rphi_folder)\n",
    "print (\"Created \", tracks_folder)\n",
    "#TODO: copy input files to this folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the datastore\n",
    "* Use the default datastore\n",
    "* Register your own datastore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading C:\\workspace\\neusomatic\\test\\NeuSomatic_ensemble.vcf\n",
      "Uploading C:\\workspace\\neusomatic\\test\\NeuSomatic_standalone.vcf\n",
      "Uploading C:\\workspace\\neusomatic\\test\\docker_test.sh\n",
      "Uploading C:\\workspace\\neusomatic\\test\\ensemble.tsv\n",
      "Uploading C:\\workspace\\neusomatic\\test\\normal.bam\n",
      "Uploading C:\\workspace\\neusomatic\\test\\normal.bam.bai\n",
      "Uploading C:\\workspace\\neusomatic\\test\\region.bed\n",
      "Uploading C:\\workspace\\neusomatic\\test\\run_test.sh\n",
      "Uploading C:\\workspace\\neusomatic\\test\\tumor.bam\n",
      "Uploading C:\\workspace\\neusomatic\\test\\tumor.bam.bai\n",
      "Uploaded C:\\workspace\\neusomatic\\test\\tumor.bam.bai, 1 files out of an estimated total of 10\n",
      "Uploaded C:\\workspace\\neusomatic\\test\\NeuSomatic_standalone.vcf, 2 files out of an estimated total of 10\n",
      "Uploaded C:\\workspace\\neusomatic\\test\\region.bed, 3 files out of an estimated total of 10\n",
      "Uploaded C:\\workspace\\neusomatic\\test\\ensemble.tsv, 4 files out of an estimated total of 10\n",
      "Uploaded C:\\workspace\\neusomatic\\test\\NeuSomatic_ensemble.vcf, 5 files out of an estimated total of 10\n",
      "Uploaded C:\\workspace\\neusomatic\\test\\docker_test.sh, 6 files out of an estimated total of 10\n",
      "Uploaded C:\\workspace\\neusomatic\\test\\normal.bam.bai, 7 files out of an estimated total of 10\n",
      "Uploaded C:\\workspace\\neusomatic\\test\\run_test.sh, 8 files out of an estimated total of 10\n",
      "Uploaded C:\\workspace\\neusomatic\\test\\normal.bam, 9 files out of an estimated total of 10\n",
      "Uploaded C:\\workspace\\neusomatic\\test\\tumor.bam, 10 files out of an estimated total of 10\n",
      "Uploaded to  AzureBlob . Account Name: neusomaticws4311691687 . Container Name: neusomatic-data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azureml.data\n",
    "from azureml.data.azure_storage_datastore import AzureFileDatastore, AzureBlobDatastore\n",
    "\n",
    "#Load test data\n",
    "source_folder='C:\\\\workspace\\\\neusomatic\\\\test'\n",
    "container_name = 'neusomatic-data'\n",
    "my_storage_account_name = 'neusomaticws4311691687'\n",
    "\n",
    "# From Azure Portal->storage->Signed signatures\n",
    "\n",
    "my_storage_key='longkey=='\n",
    "\n",
    "dsname='ds_test'\n",
    "ds_test = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                             datastore_name=dsname, \n",
    "                                             container_name=container_name,\n",
    "                                             account_name=my_storage_account_name, \n",
    "                                             #sas_token=sas_token,                                             \n",
    "                                             account_key=my_storage_key,\n",
    "                                             create_if_not_exists=True,\n",
    "                                                 overwrite=True)\n",
    "\n",
    "#ds.upload(src_dir=data_folder, target_path='lhcb_data', overwrite=True, show_progress=True)\n",
    "ds_test.upload(src_dir=source_folder, target_path=container_name, overwrite=True, show_progress=True)\n",
    "\n",
    "print('Uploaded to ', ds_test.datastore_type, '. Account Name:', ds_test.account_name, '. Container Name:', ds_test.container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpOperationError",
     "evalue": "Operation returned an invalid status code 'Update to datastore is not allowed. Only credentials of a datastore can be updated.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpOperationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\azureml\\data\\datastore_client.py\u001b[0m in \u001b[0;36m_register\u001b[1;34m(ws, dto, create_if_not_exists, skip_validation, overwrite, auth, host)\u001b[0m\n\u001b[0;32m    446\u001b[0m             client.data_store.create(ws._subscription_id, ws._resource_group, ws._workspace_name,\n\u001b[1;32m--> 447\u001b[1;33m                                      dto, create_if_not_exists, skip_validation)\n\u001b[0m\u001b[0;32m    448\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mHttpOperationError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\azureml\\_restclient\\operations\\data_store_operations.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, subscription_id, resource_group_name, workspace_name, dto, create_if_not_exists, skip_validation, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHttpOperationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHttpOperationError\u001b[0m: Operation returned an invalid status code 'Another datastore with the same name already exists but with different values. Please use patch to u'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mHttpOperationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-1729169763dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m                                              \u001b[1;31m#sas_token=sas_token,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                                              \u001b[0mcreate_if_not_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                                                 overwrite=True)\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mds_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msource_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontainer_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\azureml\\core\\datastore.py\u001b[0m in \u001b[0;36mregister_azure_blob_container\u001b[1;34m(workspace, datastore_name, container_name, account_name, sas_token, account_key, protocol, endpoint, overwrite, create_if_not_exists, skip_validation)\u001b[0m\n\u001b[0;32m    139\u001b[0m                                                                  \u001b[0maccount_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msas_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccount_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                                                                  \u001b[0mendpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_if_not_exists\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                                                                  skip_validation)\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\azureml\\data\\datastore_client.py\u001b[0m in \u001b[0;36mregister_azure_blob_container\u001b[1;34m(workspace, datastore_name, container_name, account_name, sas_token, account_key, protocol, endpoint, overwrite, create_if_not_exists, skip_validation)\u001b[0m\n\u001b[0;32m     89\u001b[0m         return _DatastoreClient._register_azure_storage(\n\u001b[0;32m     90\u001b[0m             \u001b[0mworkspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatastore_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAZURE_BLOB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccount_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcredential_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             sas_token or account_key, protocol, endpoint, overwrite, create_if_not_exists, skip_validation)\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\azureml\\data\\datastore_client.py\u001b[0m in \u001b[0;36m_register_azure_storage\u001b[1;34m(ws, datastore_name, storage_type, container_name, account_name, credential_type, credential, protocol, endpoint, overwrite, create_if_not_exists, skip_validation, auth, host)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mmodule_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Converted data into DTO\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         return _DatastoreClient._register(ws=ws, dto=datastore, create_if_not_exists=create_if_not_exists,\n\u001b[1;32m--> 368\u001b[1;33m                                           skip_validation=skip_validation, overwrite=overwrite, auth=auth, host=host)\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\azureml\\data\\datastore_client.py\u001b[0m in \u001b[0;36m_register\u001b[1;34m(ws, dto, create_if_not_exists, skip_validation, overwrite, auth, host)\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_DatastoreClient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_client\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 client.data_store.update(dto.name, ws._subscription_id, ws._resource_group,\n\u001b[1;32m--> 453\u001b[1;33m                                          ws._workspace_name, dto, create_if_not_exists, skip_validation)\n\u001b[0m\u001b[0;32m    454\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m                 module_logger.error(\"Registering datastore failed with {} error code and error message\\n{}\"\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\azureml\\_restclient\\operations\\data_store_operations.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, name, subscription_id, resource_group_name, workspace_name, dto, create_if_not_exists, skip_validation, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHttpOperationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHttpOperationError\u001b[0m: Operation returned an invalid status code 'Update to datastore is not allowed. Only credentials of a datastore can be updated.'"
     ]
    }
   ],
   "source": [
    "#Load resource data\n",
    "source_folder='C:\\\\workspace\\\\neusomatic\\\\resources'\n",
    "container_name = 'neusomatic-resources'\n",
    "my_storage_account_name = 'neusomaticws4311691687'\n",
    "\n",
    "dsname='ds_res'\n",
    "ds_res = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                             datastore_name=dsname, \n",
    "                                             container_name=container_name,\n",
    "                                             account_name=my_storage_account_name, \n",
    "                                             account_key=my_storage_key,\n",
    "                                             #sas_token=sas_token,                                             \n",
    "                                             create_if_not_exists=True,\n",
    "                                                overwrite=True)\n",
    "\n",
    "ds_res.upload(src_dir=source_folder, target_path=container_name, overwrite=False, show_progress=True)\n",
    "\n",
    "print('Uploaded to ', ds_res.datastore_type, '. Account Name:', ds_res.account_name, '. Container Name:', ds_res.container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_48.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_33.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_0.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_28.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_45.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_26.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_19.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_32.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_47.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_16.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_1.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_6.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_31.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_5.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_15.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_2.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_39.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_44.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_43.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_38.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_29.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_22.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_41.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_49.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_30.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_18.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_8.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_46.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_20.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_10.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_7.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_25.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_19.dat, 1 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_15.dat, 2 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_11.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_12.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_45.dat, 3 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_13.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_43.dat, 4 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_14.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_16.dat, 5 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_17.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_47.dat, 6 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_21.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_44.dat, 7 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_23.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_41.dat, 8 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_24.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_26.dat, 9 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_27.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_0.dat, 10 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_3.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_10.dat, 11 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_34.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_46.dat, 12 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_35.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_48.dat, 13 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_36.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_39.dat, 14 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_37.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_49.dat, 15 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_4.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_5.dat, 16 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_40.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_18.dat, 17 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_42.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_2.dat, 18 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_50.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_22.dat, 19 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_20.dat, 20 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_25.dat, 21 files out of an estimated total of 52\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_51.dat\n",
      "Uploading /home/cerndev/common/azure/data/rphi/rphi_eval_module_9.dat\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_8.dat, 22 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_7.dat, 23 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_6.dat, 24 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_33.dat, 25 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_32.dat, 26 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_28.dat, 27 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_1.dat, 28 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_38.dat, 29 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_30.dat, 30 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_29.dat, 31 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_31.dat, 32 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_4.dat, 33 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_40.dat, 34 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_50.dat, 35 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_51.dat, 36 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_42.dat, 37 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_9.dat, 38 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_21.dat, 39 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_14.dat, 40 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_23.dat, 41 files out of an estimated total of 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_17.dat, 42 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_13.dat, 43 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_11.dat, 44 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_36.dat, 45 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_24.dat, 46 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_27.dat, 47 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_34.dat, 48 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_3.dat, 49 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_12.dat, 50 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_37.dat, 51 files out of an estimated total of 52\n",
      "Uploaded /home/cerndev/common/azure/data/rphi/rphi_eval_module_35.dat, 52 files out of an estimated total of 52\n",
      "Uploaded to  AzureBlob . Account Name: lhcbstorage . Container Name: rphi\n"
     ]
    }
   ],
   "source": [
    "#Load rphi data\n",
    "source_folder=rphi_folder\n",
    "container_name = 'rphi'\n",
    "dsname='ds_rphi'\n",
    "my_storage_account_name = 'lhcbstorage'\n",
    "\n",
    "ds_rphi = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                             datastore_name=dsname, \n",
    "                                             container_name=container_name,\n",
    "                                             account_name=my_storage_account_name, \n",
    "                                             account_key=my_storage_key,\n",
    "                                             overwrite=True,\n",
    "                                             create_if_not_exists=True)\n",
    "\n",
    " \n",
    "ds_rphi.upload(src_dir=source_folder, target_path=container_name, overwrite=False, show_progress=True)\n",
    "\n",
    "print('Uploaded to ', ds_rphi.datastore_type, '. Account Name:', ds_rphi.account_name, '. Container Name:', ds_rphi.container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
